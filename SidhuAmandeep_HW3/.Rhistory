#I repeated this function here as the rmd file cannot find the function without
#it
sim_poly_data <- function(n, noise_sd) {
# create a grid of x,y values
x <- y <- seq(0, 1, length.out = n)
xy <- expand.grid(x, y)
# define the polynomial function - arbitrary (can change)
poly_func <- function(x, y) {
1 + x + y + x^2 + y^2 + x*y + x^3 + y^3 + x*y^2 + x^2*y
}
# simulate z values from the polynomial function plus Gaussian noise
z <- poly(xy[,1], xy[,2]) + rnorm(n^2, mean = 0, sd = noise_sd)
# return the simulated data as a data frame
return(data.frame(x = xy[,1], y = xy[,2], z = z))
}
library(mgcv)
n <- 50
sd <- 0.1
num_sims <- 250
# Initialize variables as a vector to store results after computation
times_gcv <- rep(0, num_sims)
times_reml <- rep(0, num_sims)
biases_gcv <- rep(0, num_sims)
biases_reml <- rep(0, num_sims)
variances_gcv <- rep(0, num_sims)
variances_reml <- rep(0, num_sims)
mse_gcv <- rep(0, num_sims)
mse_reml <- rep(0, num_sims)
for (i in 1:num_sims) {
# Simulate data
data <- simulate_data(n, sd)
# Fit GAM with GCV.Cp
start_time <- Sys.time()
fit_gcv <- gam(z ~ te(x, y, bs = "tp", k = 10), data = data, method = "GCV.Cp")
end_time <- Sys.time()
times_gcv[i] <- end_time - start_time
# Fit GAM with REML
start_time <- Sys.time()
fit_reml <- gam(z ~ te(x, y, bs = "tp", k = 10), data = data, method = "REML")
end_time <- Sys.time()
times_reml[i] <- end_time - start_time
# Compute predictions and errors for the gcv and reml vectors
pred_gcv <- predict(fit_gcv, newdata = data, type = "response")
pred_reml <- predict(fit_reml, newdata = data, type = "response")
bias_gcv <- mean(pred_gcv - data$z)
bias_reml <- mean(pred_reml - data$z)
var_gcv <- var(pred_gcv - data$z)
var_reml <- var(pred_reml - data$z)
mse_gcv[i] <- mean((pred_gcv - data$z)^2)
mse_reml[i] <- mean((pred_reml - data$z)^2)
# Store results in their respective vectors
biases_gcv[i] <- bias_gcv
biases_reml[i] <- bias_reml
variances_gcv[i] <- var_gcv
variances_reml[i] <- var_reml
}
sim_poly_data <- function(n, noise_sd) {
# create a grid of x,y values
x <- y <- seq(0, 1, length.out = n)
xy <- expand.grid(x, y)
# define the polynomial function - arbitrary (can change)
poly_func <- function(x, y) {
1 + x + y + x^2 + y^2 + x*y + x^3 + y^3 + x*y^2 + x^2*y
}
# simulate z values from the polynomial function plus Gaussian noise
z <- poly(xy[,1], xy[,2]) + rnorm(n^2, mean = 0, sd = noise_sd)
# return the simulated data as a data frame
return(data.frame(x = xy[,1], y = xy[,2], z = z))
}
#I repeated this function
sim_poly_data <- function(n, noise_sd) {
# create a grid of x,y values
x <- y <- seq(0, 1, length.out = n)
xy <- expand.grid(x, y)
# define the polynomial function - arbitrary (can change)
poly_func <- function(x, y) {
1 + x + y + x^2 + y^2 + x*y + x^3 + y^3 + x*y^2 + x^2*y
}
# simulate z values from the polynomial function plus Gaussian noise
z <- poly(xy[,1], xy[,2]) + rnorm(n^2, mean = 0, sd = noise_sd)
# return the simulated data as a data frame
return(data.frame(x = xy[,1], y = xy[,2], z = z))
}
library(mgcv)
n <- 50
sd <- 0.1
num_sims <- 250
# Initialize variables as a vector to store results after computation
times_gcv <- rep(0, num_sims)
times_reml <- rep(0, num_sims)
biases_gcv <- rep(0, num_sims)
biases_reml <- rep(0, num_sims)
variances_gcv <- rep(0, num_sims)
variances_reml <- rep(0, num_sims)
mse_gcv <- rep(0, num_sims)
mse_reml <- rep(0, num_sims)
for (i in 1:num_sims) {
# Simulate data
data <- sim_poly_data(n, sd)
# Fit GAM with GCV.Cp
start_time <- Sys.time()
fit_gcv <- gam(z ~ te(x, y, bs = "tp", k = 10), data = data, method = "GCV.Cp")
end_time <- Sys.time()
times_gcv[i] <- end_time - start_time
# Fit GAM with REML
start_time <- Sys.time()
fit_reml <- gam(z ~ te(x, y, bs = "tp", k = 10), data = data, method = "REML")
end_time <- Sys.time()
times_reml[i] <- end_time - start_time
# Compute predictions and errors for the gcv and reml vectors
pred_gcv <- predict(fit_gcv, newdata = data, type = "response")
pred_reml <- predict(fit_reml, newdata = data, type = "response")
bias_gcv <- mean(pred_gcv - data$z)
bias_reml <- mean(pred_reml - data$z)
var_gcv <- var(pred_gcv - data$z)
var_reml <- var(pred_reml - data$z)
mse_gcv[i] <- mean((pred_gcv - data$z)^2)
mse_reml[i] <- mean((pred_reml - data$z)^2)
# Store results in their respective vectors
biases_gcv[i] <- bias_gcv
biases_reml[i] <- bias_reml
variances_gcv[i] <- var_gcv
variances_reml[i] <- var_reml
}
#I repeated this function
sim_poly_data <- function(n, noise_sd) {
# create a grid of x,y values
x <- y <- seq(0, 1, length.out = n)
xy <- expand.grid(x, y)
# define the polynomial function - arbitrary (can change)
poly_func <- function(x, y) {
1 + x + y + x^2 + y^2 + x*y + x^3 + y^3 + x*y^2 + x^2*y
}
# simulate z values from the polynomial function plus Gaussian noise
z <- poly(xy[,1], xy[,2]) + rnorm(n^2, mean = 0, sd = noise_sd)
# return the simulated data as a data frame
return(data.frame(x = xy[,1], y = xy[,2], z = z))
}
library(mgcv)
n <- 50
sd <- 0.1
num_sims <- 250
# Initialize variables as a vector to store results after computation
times_gcv <- rep(0, num_sims)
times_reml <- rep(0, num_sims)
biases_gcv <- rep(0, num_sims)
biases_reml <- rep(0, num_sims)
variances_gcv <- rep(0, num_sims)
variances_reml <- rep(0, num_sims)
mse_gcv <- rep(0, num_sims)
mse_reml <- rep(0, num_sims)
for (i in 1:num_sims) {
# Simulate data
data <- sim_poly_data(n, sd)
# Fit GAM with GCV.Cp
start_time <- Sys.time()
fit_gcv <- gam(z ~ te(x, y, bs = "tp", k = 10), data = data, method = "GCV.Cp")
end_time <- Sys.time()
times_gcv[i] <- end_time - start_time
# Fit GAM with REML
start_time <- Sys.time()
fit_reml <- gam(z ~ te(x, y, bs = "tp", k = 10), data = data, method = "REML")
end_time <- Sys.time()
times_reml[i] <- end_time - start_time
# Compute predictions and errors for the gcv and reml vectors
pred_gcv <- predict(fit_gcv, newdata = data, type = "response")
pred_reml <- predict(fit_reml, newdata = data, type = "response")
bias_gcv <- mean(pred_gcv - data$z)
bias_reml <- mean(pred_reml - data$z)
var_gcv <- var(pred_gcv - data$z)
var_reml <- var(pred_reml - data$z)
mse_gcv[i] <- mean((pred_gcv - data$z)^2)
mse_reml[i] <- mean((pred_reml - data$z)^2)
# Store results in their respective vectors
biases_gcv[i] <- bias_gcv
biases_reml[i] <- bias_reml
variances_gcv[i] <- var_gcv
variances_reml[i] <- var_reml
}
#I repeated this function
sim_poly_data <- function(n, noise_sd) {
# create a grid of x,y values
x <- y <- seq(0, 1, length.out = n)
xy <- expand.grid(x, y)
# define the polynomial function - arbitrary (can change)
poly_func <- function(x, y) {
1 + x + y + x^2 + y^2 + x*y + x^3 + y^3 + x*y^2 + x^2*y
}
# simulate z values from the polynomial function plus Gaussian noise
z <- poly(xy[,1], xy[,2]) + rnorm(n^2, mean = 0, sd = noise_sd)
# return the simulated data as a data frame
return(data.frame(x = xy[,1], y = xy[,2], z = z))
}
library(mgcv)
n <- 50
sd <- 0.1
num_sims <- 250
# Initialize variables as a vector to store results after computation
times_gcv <- rep(0, num_sims)
times_reml <- rep(0, num_sims)
biases_gcv <- rep(0, num_sims)
biases_reml <- rep(0, num_sims)
variances_gcv <- rep(0, num_sims)
variances_reml <- rep(0, num_sims)
mse_gcv <- rep(0, num_sims)
mse_reml <- rep(0, num_sims)
for (i in 1:num_sims) {
# Simulate data
data <- sim_poly_data(n, sd)
# Fit GAM with GCV.Cp
start_time <- Sys.time()
fit_gcv <- gam(z ~ te(x, y, bs = "tp", k = 10), data = data, method = "GCV.Cp")
end_time <- Sys.time()
times_gcv[i] <- end_time - start_time
# Fit GAM with REML
start_time <- Sys.time()
fit_reml <- gam(z ~ te(x, y, bs = "tp", k = 10), data = data, method = "REML")
end_time <- Sys.time()
times_reml[i] <- end_time - start_time
# Compute predictions and errors for the gcv and reml vectors
pred_gcv <- predict(fit_gcv, newdata = data, type = "response")
pred_reml <- predict(fit_reml, newdata = data, type = "response")
bias_gcv <- mean(pred_gcv - data$z)
bias_reml <- mean(pred_reml - data$z)
var_gcv <- var(pred_gcv - data$z)
var_reml <- var(pred_reml - data$z)
mse_gcv[i] <- mean((pred_gcv - data$z)^2)
mse_reml[i] <- mean((pred_reml - data$z)^2)
# Store results in their respective vectors
biases_gcv[i] <- bias_gcv
biases_reml[i] <- bias_reml
variances_gcv[i] <- var_gcv
variances_reml[i] <- var_reml
}
sim_poly_data <- function(n, noise_sd) {
# create a grid of x,y values
x <- y <- seq(0, 1, length.out = n)
xy <- expand.grid(x, y)
# define the polynomial function - arbitrary (can change)
poly_func <- function(x, y) {
1 + x + y + x^2 + y^2 + x*y + x^3 + y^3 + x*y^2 + x^2*y
}
# simulate z values from the polynomial function plus Gaussian noise
z <- poly_func(xy[,1], xy[,2]) + rnorm(n^2, mean = 0, sd = noise_sd)
# return the simulated data as a data frame
return(data.frame(x = xy[,1], y = xy[,2], z = z))
}
#I repeated this function
sim_poly_data <- function(n, noise_sd) {
# create a grid of x,y values
x <- y <- seq(0, 1, length.out = n)
xy <- expand.grid(x, y)
# define the polynomial function - arbitrary (can change)
poly_func <- function(x, y) {
1 + x + y + x^2 + y^2 + x*y + x^3 + y^3 + x*y^2 + x^2*y
}
# simulate z values from the polynomial function plus Gaussian noise
z <- poly_func(xy[,1], xy[,2]) + rnorm(n^2, mean = 0, sd = noise_sd)
# return the simulated data as a data frame
return(data.frame(x = xy[,1], y = xy[,2], z = z))
}
library(mgcv)
n <- 50
sd <- 0.1
num_sims <- 250
# Initialize variables as a vector to store results after computation
times_gcv <- rep(0, num_sims)
times_reml <- rep(0, num_sims)
biases_gcv <- rep(0, num_sims)
biases_reml <- rep(0, num_sims)
variances_gcv <- rep(0, num_sims)
variances_reml <- rep(0, num_sims)
mse_gcv <- rep(0, num_sims)
mse_reml <- rep(0, num_sims)
for (i in 1:num_sims) {
# Simulate data
data <- sim_poly_data(n, sd)
# Fit GAM with GCV.Cp
start_time <- Sys.time()
fit_gcv <- gam(z ~ te(x, y, bs = "tp", k = 10), data = data, method = "GCV.Cp")
end_time <- Sys.time()
times_gcv[i] <- end_time - start_time
# Fit GAM with REML
start_time <- Sys.time()
fit_reml <- gam(z ~ te(x, y, bs = "tp", k = 10), data = data, method = "REML")
end_time <- Sys.time()
times_reml[i] <- end_time - start_time
# Compute predictions and errors for the gcv and reml vectors
pred_gcv <- predict(fit_gcv, newdata = data, type = "response")
pred_reml <- predict(fit_reml, newdata = data, type = "response")
bias_gcv <- mean(pred_gcv - data$z)
bias_reml <- mean(pred_reml - data$z)
var_gcv <- var(pred_gcv - data$z)
var_reml <- var(pred_reml - data$z)
mse_gcv[i] <- mean((pred_gcv - data$z)^2)
mse_reml[i] <- mean((pred_reml - data$z)^2)
# Store results in their respective vectors
biases_gcv[i] <- bias_gcv
biases_reml[i] <- bias_reml
variances_gcv[i] <- var_gcv
variances_reml[i] <- var_reml
}
# Compute average results for both gcv and reml as instructed
avg_time_gcv <- mean(times_gcv)
avg_time_reml <- mean(times_reml)
avg_bias_gcv <- mean(biases_gcv)
avg_bias_reml <- mean(biases_reml)
avg_var_gcv <- mean(variances_gcv)
avg_var_reml <- mean(variances_reml)
avg_mse_gcv <- mean(mse_gcv)
avg_mse_reml <- mean(mse_reml)
results <- data.frame(method = c("GCV.Cp", "REML"),
avg_time = c(avg_time_gcv, avg_time_reml),
bias = c(avg_bias_gcv, avg_bias_reml),
variance = c(avg_var_gcv, avg_var_reml),
mse = c(avg_mse_gcv, avg_mse_reml))
results
getwd(0)
getwd()
setwd("C:/Users/User/Documents/Stats_790_Assignment3")
#here i will import the plots just because that chunk takes 20 minutes to run
knitr::include_graphics("Capture.png")
#implement the truncated polynomial spline function from lecture
truncpolyspline <- function (x, k, natural) {
knots = quantile(x, probs = seq(0.27, 0.95, length = k))
trunc_fun <- function(k)
(x > k)*(x-k)^3
if (natural) { #this is when natural constraint is true
#Build Design Matrix
S <- matrix(0, nrow = length(x), ncol = k)
#Begin injecting the appropriate values of S into the function
S[,1] <- x
for (j in 2:(k-1)) {
#This is the magic (i.e. here we are adding the linear constraint)
S[, j] <- ((x > knots[j-1])*(x - knots [j-1])^3  -
(x > knots[k])*(x - knots[k])^3)/(knots[k] - knots[j-1]) -
((x - knots [k-1])^3*(x>knots[k-1])  -
(x - knots[k])^3*(x>knots[k]))/(knots[k] - knots[k-1])
}
} else{ #this is when natural constraint is false
S <- sapply(knots, trunc_fun)
S <-cbind(x, x^2, x^3, S)
}
return(S)
}
#Create a vector - I used the same as in class
xvec <- seq(0,100, length = 100)
#Apply the function with both values of natural
tS1 <- truncpolyspline(xvec, k = 5, natural = TRUE)
tS2 <- truncpolyspline(xvec, k = 5+4, natural = FALSE)
#Use matplot to plot the graphs
matplot(scale(tS1), type = 'l', main = "Natural Spline")
matplot(scale(tS2), type = 'l', main = "Truncated Polynomial Spline")
#implement the truncated polynomial spline function from lecture
truncpolyspline <- function (x, k, natural) {
knots = quantile(x, probs = seq(0.27, 0.95, length = k))
trunc_fun <- function(k)
(x > k)*(x-k)^3
if (natural) { #this is when natural constraint is true
#Build Design Matrix
S <- matrix(0, nrow = length(x), ncol = k)
#Begin injecting the appropriate values of S into the function
S[,1] <- x
for (j in 2:(k-1)) {
#This is the magic (i.e. here we are adding the linear constraint)
S[, j] <- ((x > knots[j-1])*(x - knots [j-1])^3  -
(x > knots[k])*(x - knots[k])^3)/(knots[k] - knots[j-1]) -
((x - knots [k-1])^3*(x>knots[k-1])  -
(x - knots[k])^3*(x>knots[k]))/(knots[k] - knots[k-1])
}
} else{ #this is when natural constraint is false
S <- sapply(knots, trunc_fun)
S <-cbind(x, x^2, x^3, S)
}
return(S)
}
#Create a vector - I used the same as in class
xvec <- seq(0,100, length = 100)
#Apply the function with both values of natural
tS1 <- truncpolyspline(xvec, k = 5, natural = TRUE)
tS2 <- truncpolyspline(xvec, k = 1, natural = FALSE)
#Use matplot to plot the graphs
matplot(scale(tS1), type = 'l', main = "Natural Spline")
matplot(scale(tS2), type = 'l', main = "Truncated Polynomial Spline")
#implement the truncated polynomial spline function from lecture
truncpolyspline <- function (x, k, natural) {
knots = quantile(x, probs = seq(0.27, 0.95, length = k))
trunc_fun <- function(k)
(x > k)*(x-k)^3
if (natural) { #this is when natural constraint is true
#Build Design Matrix
S <- matrix(0, nrow = length(x), ncol = k)
#Begin injecting the appropriate values of S into the function
S[,1] <- x
for (j in 2:(k-1)) {
#This is the magic (i.e. here we are adding the linear constraint)
S[, j] <- ((x > knots[j-1])*(x - knots [j-1])^3  -
(x > knots[k])*(x - knots[k])^3)/(knots[k] - knots[j-1]) -
((x - knots [k-1])^3*(x>knots[k-1])  -
(x - knots[k])^3*(x>knots[k]))/(knots[k] - knots[k-1])
}
} else{ #this is when natural constraint is false
S <- sapply(knots, trunc_fun)
S <-cbind(x, x^2, x^3, S)
}
return(S)
}
#Create a vector - I used the same as in class
xvec <- seq(0,100, length = 100)
#Apply the function with both values of natural
tS1 <- truncpolyspline(xvec, k = 9, natural = TRUE)
#Use k - 4 to get same number of lines as the previous natural spline function
tS2 <- truncpolyspline(xvec, k = 5, natural = FALSE)
#Use matplot to plot the graphs
matplot(scale(tS1), type = 'l', main = "Natural Spline")
matplot(scale(tS2), type = 'l', main = "Truncated Polynomial Spline")
#implement the truncated polynomial spline function from lecture
truncpolyspline <- function (x, k, natural) {
knots = quantile(x, probs = seq(0.27, 0.95, length = k))
trunc_fun <- function(k)
(x > k)*(x-k)^3
if (natural) { #this is when natural constraint is true
#Build Design Matrix
S <- matrix(0, nrow = length(x), ncol = k)
#Begin injecting the appropriate values of S into the function
S[,1] <- x
for (j in 2:(k-1)) {
#This is the magic (i.e. here we are adding the linear constraint)
S[, j] <- ((x > knots[j-1])*(x - knots [j-1])^3  -
(x > knots[k])*(x - knots[k])^3)/(knots[k] - knots[j-1]) -
((x - knots [k-1])^3*(x>knots[k-1])  -
(x - knots[k])^3*(x>knots[k]))/(knots[k] - knots[k-1])
}
} else{ #this is when natural constraint is false
S <- sapply(knots, trunc_fun)
S <-cbind(x, x^2, x^3, S)
}
return(S)
}
#Create a vector - I used the same as in class
xvec <- seq(0,100, length = 100)
#Apply the function with both values of natural (use K + 4) for natural = TRUE
#to ensure the number of lines within the plots are the same
tS1 <- truncpolyspline(xvec, k = 5, natural = TRUE)
tS2 <- truncpolyspline(xvec, k = 5, natural = FALSE)
#Use matplot to plot the graphs
matplot(scale(tS1), type = 'l', main = "Natural Spline")
matplot(scale(tS2), type = 'l', main = "Truncated Polynomial Spline")
#implement the truncated polynomial spline function from lecture
truncpolyspline <- function (x, k, natural) {
knots = quantile(x, probs = seq(0.27, 0.95, length = k))
trunc_fun <- function(k)
(x > k)*(x-k)^3
if (natural) { #this is when natural constraint is true
#Build Design Matrix
S <- matrix(0, nrow = length(x), ncol = k)
#Begin injecting the appropriate values of S into the function
S[,1] <- x
for (j in 2:(k-1)) {
#This is the magic (i.e. here we are adding the linear constraint)
S[, j] <- ((x > knots[j-1])*(x - knots [j-1])^3  -
(x > knots[k])*(x - knots[k])^3)/(knots[k] - knots[j-1]) -
((x - knots [k-1])^3*(x>knots[k-1])  -
(x - knots[k])^3*(x>knots[k]))/(knots[k] - knots[k-1])
}
} else{ #this is when natural constraint is false
S <- sapply(knots, trunc_fun)
S <-cbind(x, x^2, x^3, S)
}
return(S)
}
#Create a vector - I used the same as in class
xvec <- seq(0,100, length = 100)
#Apply the function with both values of natural (use K + 4) for natural = TRUE
#to ensure the number of lines within the plots are the same
tS1 <- truncpolyspline(xvec, k = 5, natural = TRUE)
tS2 <- truncpolyspline(xvec, k = 9, natural = FALSE)
#Use matplot to plot the graphs
matplot(scale(tS1), type = 'l', main = "Natural Spline")
matplot(scale(tS2), type = 'l', main = "Truncated Polynomial Spline")
#implement the truncated polynomial spline function from lecture
truncpolyspline <- function (x, k, natural) {
knots = quantile(x, probs = seq(0.27, 0.95, length = k))
trunc_fun <- function(k)
(x > k)*(x-k)^3
if (natural) { #this is when natural constraint is true
#Build Design Matrix
S <- matrix(0, nrow = length(x), ncol = k)
#Begin injecting the appropriate values of S into the function
S[,1] <- x
for (j in 2:(k-1)) {
#This is the magic (i.e. here we are adding the linear constraint)
S[, j] <- ((x > knots[j-1])*(x - knots [j-1])^3  -
(x > knots[k])*(x - knots[k])^3)/(knots[k] - knots[j-1]) -
((x - knots [k-1])^3*(x>knots[k-1])  -
(x - knots[k])^3*(x>knots[k]))/(knots[k] - knots[k-1])
}
} else{ #this is when natural constraint is false
S <- sapply(knots, trunc_fun)
S <-cbind(x, x^2, x^3, S)
}
return(S)
}
#Create a vector - I used the same as in class
xvec <- seq(0,100, length = 100)
#Apply the function with both values of natural (use K + 4) for natural = TRUE
#to ensure the number of lines within the plots are the same
tS1 <- truncpolyspline(xvec, k = 5, natural = TRUE)
tS2 <- truncpolyspline(xvec, k = 1, natural = FALSE)
#Use matplot to plot the graphs
matplot(scale(tS1), type = 'l', main = "Natural Spline")
matplot(scale(tS2), type = 'l', main = "Truncated Polynomial Spline")
